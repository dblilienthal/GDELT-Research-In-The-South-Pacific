{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains how i created multiple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query used to pull all events from the South Pacific from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    events.GLOBALEVENTID, SQLDATE, MonthYear, Actor1Name, Actor1CountryCode, Actor1Geo_Type, Actor1Geo_FeatureID, Actor2Name, Actor2CountryCode, Actor2Geo_Type, Actor2Geo_FeatureID, EventCode, GoldsteinScale, NumMentions, NumSources, NumArticles, AvgTone, Actor1Geo_FullName, Actor1Geo_CountryCode, Actor2Geo_FullName, Actor2Geo_CountryCode, ActionGeo_FullName, ActionGeo_CountryCode, ActionGeo_ADM1Code, ActionGeo_ADM2Code, ActionGeo_Type, ActionGeo_FeatureID, SOURCEURL, MentionTimeDate, MentionType, MentionSourceName, MentionIdentifier, SentenceID, Actor1CharOffset, Actor2CharOffset, ActionCharOffset, InRawText, Confidence,\tMentionDocLen, MentionDocTone, SourceCollectionIdentifier, SourceCommonName, DocumentIdentifier, Themes, V2Themes, Locations, V2Locations, Persons, V2Persons, Organizations, V2Organizations, V2Tone, AllNames\n",
    "FROM \n",
    "  `gdelt-bq.gdeltv2.eventmentions_partitioned` as eventmentions join `gdelt-bq.gdeltv2.events_partitioned` as events \n",
    "    ON eventmentions.GLOBALEVENTID = events.GLOBALEVENTID inner join `gdelt-bq.gdeltv2.gkg_partitioned`as GKG on eventmentions.MentionIdentifier = GKG.DocumentIdentifier\n",
    "WHERE \n",
    "  ActionGeo_ADM1Code like 'FM%' -- Micronesia\n",
    "  OR ActionGeo_ADM1Code like 'FJ%' -- Fiji\n",
    "  OR ActionGeo_ADM1Code like 'KR%' -- Kiribati\n",
    "  OR ActionGeo_ADM1Code like 'RM%' -- Marshall Islands\n",
    "  OR ActionGeo_ADM1Code like 'NR%' -- Nauru\n",
    "  OR ActionGeo_ADM1Code like 'PS%' -- Palau\n",
    "  OR ActionGeo_ADM1Code like 'PP%' -- Papua New Guinea\n",
    "  OR ActionGeo_ADM1Code like 'WS%' -- Samoa\n",
    "  OR ActionGeo_ADM1Code like 'BP%' -- Solomon Islands\n",
    "  OR ActionGeo_ADM1Code like 'TN%' -- Tonga\n",
    "  OR ActionGeo_ADM1Code like 'TV%' -- Tuvalu\n",
    "  OR ActionGeo_ADM1Code like 'NH%' -- Vanuatu\n",
    "  OR ActionGeo_ADM1Code like 'CW%' -- Cook Islands\n",
    "  OR ActionGeo_ADM1Code like 'NE%' -- Niue\n",
    "  OR ActionGeo_ADM1Code like 'AQ%' -- American Samoa\n",
    "  OR ActionGeo_FullName = 'Ashmore Reef, Queensland, Australia'\n",
    "  OR ActionGeo_ADM1Code like 'FQ%' -- Baker Island\n",
    "  OR ActionGeo_FullName = 'Coral Sea, Oceans (general), Oceans'\n",
    "  OR ActionGeo_FullName like 'Easter Island, V%'\n",
    "  OR ActionGeo_FullName = 'Galapagos, Imbabura, Ecuador'\n",
    "  OR ActionGeo_ADM1Code like 'FP%' -- French Polynesia\n",
    "  OR ActionGeo_ADM1Code like 'GQ%' -- Guam\n",
    "  OR ActionGeo_ADM1Code like 'HQ%' -- Howland Island\n",
    "  OR ActionGeo_ADM1Code like 'DQ%' -- Jarvis Island\n",
    "  OR ActionGeo_ADM1Code like 'JQ%' -- Johnston Atoll\n",
    "  OR ActionGeo_ADM1Code like 'KQ%' -- Kingman Reef\n",
    "  OR ActionGeo_FullName = 'Midway Island, Western Australia, Australia'\n",
    "  OR ActionGeo_ADM1Code like 'NC%' -- New Caledonia\n",
    "  OR ActionGeo_ADM1Code like 'NF%' -- Norfold Island\n",
    "  OR ActionGeo_ADM1Code like 'CQ%' -- Norther Mariana Islands\n",
    "  OR ActionGeo_FullName = 'Ogasawaramura, Tokyo, Japan'\n",
    "  OR ActionGeo_ADM1Code like 'LQ%' -- Palmyra Atoll\n",
    "  OR ActionGeo_ADM1Code = 'ID36' -- Papua, Indonesia\n",
    "  OR ActionGeo_ADM1Code like 'PC%' -- Pitcairn Islands\n",
    "  OR ActionGeo_ADM1Code like 'TL%' -- Tokelau\n",
    "  OR ActionGeo_ADM1Code like 'WQ%' -- Wake Island\n",
    "  OR ActionGeo_ADM1Code like 'WF%' -- Wallis and Futuna\n",
    "  OR ActionGeo_ADM1Code = 'ID39' -- West Papua, Indonesia\n",
    "  OR ActionGeo_FullName = 'Bonin Islands, Tokyo, Japan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of the initial pull on Oct 26, 2020, 4:30:23 PM, this table is <b>19.9 GB</b> in size and contains <b> 4323833 </b> entries <br>\n",
    "This dataset also contains a lot of extra columns that may or may not prove to be useful but are included just encase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a mini dataset from the initial pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the previous dataset is too massive to completely store in memory all the time, creating a smaller dataset from the initial dataset will allow me to do analysis faster and prevent issues where you may run out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assume: \n",
    "<em>The previous dataset is already saved as <b>df</b><br> Python libraries <b>numpy</b> (np), <b>pandas</b> (pd), and <b>sqlalchemy</b> are already imported</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '' # exact location to store the dataset along with the name \n",
    "\n",
    "useful_columns = ['SQLDATE', 'MonthYear', 'Actor1Name', 'Actor1CountryCode', \n",
    "                  'Actor2Name', 'Actor2CountryCode', 'AvgTone', 'Actor1Geo_FullName',\n",
    "                  'Actor1Geo_CountryCode', 'Actor2Geo_FullName', 'Actor2Geo_CountryCode', \n",
    "                  'ActionGeo_FullName', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code', \n",
    "                  'SOURCEURL', 'MentionSourceName', 'MentionIdentifier', 'Confidence', \n",
    "                  'MentionDocLen', 'MentionDocTone', 'SourceCommonName', 'V2Themes', 'V2Tone']\n",
    "\n",
    "pd.DataFrame(data=df[useful_columns], columns=[useful_columns]).to_csv(location, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new dataset only containing columns that are immediately useful is <b>9.22 GB</b> in size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a mini dataset only containing ENV_ themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is creating a SQL engine that converts a CSV file into an SQL file. I found that sqlalchemy was the simplest and most intuitive for me to use. There are many other options i could have choose but i stuck with the first that worked easy for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SQL engine \n",
    "engine = create_engine('sqlite://', echo=False)\n",
    "\n",
    "# df is the name of the dataset already created through pandas. \n",
    "# 'df' (inside the parentheses) is the name of the dataset you will query within sqlalchemy. \n",
    "# This name is arbitrary and you can name it whatever you want.\n",
    "df.to_sql('df', con=engine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT SQLDATE, MonthYear, Actor1Name, Actor1CountryCode, Actor2Name, \n",
    "    Actor2CountryCode, AvgTone, Actor1Geo_FullName, Actor1Geo_CountryCode, \n",
    "    Actor2Geo_FullName, Actor2Geo_CountryCode, ActionGeo_FullName, \n",
    "    ActionGeo_CountryCode, ActionGeo_ADM1Code, SOURCEURL, MentionSourceName, \n",
    "    MentionIdentifier, Confidence, MentionDocLen, MentionDocTone, \n",
    "    SourceCommonName, V2Themes, V2Tone\n",
    "FROM df\n",
    "WHERE V2Themes LIKE '%ENV_%'\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and save the result\n",
    "temp_result = engine.execute(query).fetchall()\n",
    "# Convert result into numpy array\n",
    "temp1 = np.array(temp_result)\n",
    "\n",
    "# convert the numpy array into a dataframe and save it to some location again\n",
    "pd.DataFrame(data=temp1, columns=['SQLDATE', 'MonthYear', 'Actor1Name', 'Actor1CountryCode', \n",
    "                                  'Actor2Name', 'Actor2CountryCode', 'AvgTone', \n",
    "                                  'Actor1Geo_FullName', 'Actor1Geo_CountryCode', \n",
    "                                  'Actor2Geo_FullName', 'Actor2Geo_CountryCode', \n",
    "                                  'ActionGeo_FullName', 'ActionGeo_CountryCode', \n",
    "                                  'ActionGeo_ADM1Code', 'SOURCEURL', 'MentionSourceName', \n",
    "                                  'MentionIdentifier', 'Confidence', 'MentionDocLen', \n",
    "                                  'MentionDocTone', 'SourceCommonName', 'V2Themes', \n",
    "                                  'V2Tone'])\n",
    "                                  .to_csv(location, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is <b>2.57 GB </b> and contains <b> 877,841 </b> articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a mini dataset only containing Great Powers using Actor1/2CountryCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating this mini dataset, i used all pandas functions to create this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The great powers of interest are: <b>United States</b>, <b>China</b>, <b>Australia</b>, <b>New Zealand</b>, <b>Russia</b>, and <b>Japan</b> <br>\n",
    "Great power Actor1/2CountryCode: <b>USA</b>, <b>CHN</b>, <b>AUS</b>, <b>NZL</b>, <b>RUS</b>, and <b>JPN</b> <br>\n",
    "Great power Actor1/2Geo_CountryCode: <b>US</b>, <b>CH</b>, <b>AS</b>, <b>NZ</b>, <b>RS</b>, and <b>JA</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '' # exact location to store the dataset along with the name \n",
    "\n",
    "usa_mask = ((df['Actor1CountryCode'] == 'USA') | (df['Actor2CountryCode'] == 'USA'))\n",
    "chn_mask = ((df['Actor1CountryCode'] == 'CHN') | (df['Actor2CountryCode'] == 'CHN'))\n",
    "aus_mask = ((df['Actor1CountryCode'] == 'AUS') | (df['Actor2CountryCode'] == 'AUS'))\n",
    "nzl_mask = ((df['Actor1CountryCode'] == 'NZL') | (df['Actor2CountryCode'] == 'NZL'))\n",
    "rus_mask = ((df['Actor1CountryCode'] == 'RUS') | (df['Actor2CountryCode'] == 'RUS'))\n",
    "jpn_mask = ((df['Actor1CountryCode'] == 'JPN') | (df['Actor2CountryCode'] == 'JPN'))\n",
    "df[(usa_mask | chn_mask | aus_mask | nzl_mask | rus_mask | jpn_mask)].to_csv(location, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is <b>2.96 GB</b> and contains <b> 1,497,930 </b> articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mini dataset with Great Powers and ENV_ themes using Actor1/2CountryCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating another subset dataset containing the Great Powers (filtered using Actor1/2CountryCode), i just loaded the mini dataset that has only ENV_ themes and used the same logic underneath the <br><em> Creating a mini dataset only containing Great Powers using Actor1/2CountryCode </em> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is <b>742 MB</b> and contains <b> 277,215 </b> articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a mini dataset only containing Great Powers using Actor1/2Geo_CountryCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '' # exact location to store the dataset along with the name \n",
    "\n",
    "usa_mask = ((df['Actor1Geo_CountryCode'] == 'US') | (df['Actor2Geo_CountryCode'] == 'US'))\n",
    "chn_mask = ((df['Actor1Geo_CountryCode'] == 'CH') | (df['Actor2Geo_CountryCode'] == 'CH'))\n",
    "aus_mask = ((df['Actor1Geo_CountryCode'] == 'AS') | (df['Actor2Geo_CountryCode'] == 'AS'))\n",
    "nzl_mask = ((df['Actor1Geo_CountryCode'] == 'NZ') | (df['Actor2Geo_CountryCode'] == 'NZ'))\n",
    "rus_mask = ((df['Actor1Geo_CountryCode'] == 'RS') | (df['Actor2Geo_CountryCode'] == 'RS'))\n",
    "jpn_mask = ((df['Actor1Geo_CountryCode'] == 'JA') | (df['Actor2Geo_CountryCode'] == 'JA'))\n",
    "df[(usa_mask | chn_mask | aus_mask | nzl_mask | rus_mask | jpn_mask)].to_csv(location, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is <b>1.39 GB</b> and contains <b> 648,345 </b> articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mini dataset with Great Powers and ENV_ themes using Actor1/2Geo_CountryCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating another subset dataset containing the Great Powers (filtered using Actor1/2Geo_CountryCode), i just loaded the mini dataset that has only ENV_ themes and used the same logic underneath the <br><em> Creating a mini dataset only containing Great Powers using Actor1/2Geo_CountryCode </em> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is <b>368 MB</b> and contains <b> 125,635 </b> articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
